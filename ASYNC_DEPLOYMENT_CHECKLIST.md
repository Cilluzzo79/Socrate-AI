# Async Implementation - Deployment Checklist

## Pre-Deployment Verification

### ✅ Core Files

- [x] `celery_config.py` - Celery configuration
- [x] `tasks.py` - Async document processing task
- [x] `api_server.py` - Modified with async task queueing
- [x] `static/js/dashboard.js` - Frontend polling implementation
- [x] `Procfile` - Web service configuration
- [x] `Procfile.worker` - Worker service configuration
- [x] `docker-compose.dev.yml` - Local development setup
- [x] `requirements_multitenant.txt` - Updated with Celery/Redis

### ✅ Database Schema

- [x] `core/database.py` - Models with metadata field renamed to `doc_metadata`
- [x] `core/document_operations.py` - Multi-tenant document operations
- [x] JSON type used (compatible with SQLite and PostgreSQL)
- [x] Document status field: 'processing', 'ready', 'failed'
- [x] `processing_progress` field for progress tracking

### ✅ API Endpoints

- [x] `POST /api/documents/upload` - Queues Celery task
- [x] `GET /api/documents/<id>/status` - Lightweight polling endpoint
- [x] `GET /api/documents/<id>` - Full document details with task status
- [x] Authentication via `@require_auth` decorator

### ✅ Frontend

- [x] Upload form with progress bar
- [x] `pollDocumentStatus()` function (2-second intervals)
- [x] Progress bar updates from API
- [x] Status message display
- [x] Error handling
- [x] Auto-reload for processing documents (30-second intervals)

### ✅ Testing Tools

- [x] `test_async_processing.py` - Comprehensive test suite
- [x] `start_async_dev.bat` - Windows development startup script
- [x] `init_db.py` - Database initialization

### ✅ Documentation

- [x] `DEPLOYMENT_GUIDE.md` - Updated with Celery/Redis setup
- [x] `README_MULTITENANT.md` - Updated architecture diagram
- [x] `ASYNC_IMPLEMENTATION_SUMMARY.md` - Complete implementation details
- [x] `ASYNC_DEPLOYMENT_CHECKLIST.md` - This file

## Railway Deployment Steps

### 1. Services to Create

- [ ] Web Service (Flask API)
  - Uses `Procfile`
  - Environment variables configured

- [ ] Worker Service (Celery)
  - Uses manual start command from `Procfile.worker`
  - Connected to same repository
  - Same environment variables as web service

- [ ] Redis Database
  - Add from Railway marketplace
  - Automatically creates `REDIS_URL`

- [ ] PostgreSQL Database
  - Add from Railway marketplace
  - Automatically creates `DATABASE_URL`

### 2. Environment Variables

**Required for BOTH web and worker services:**

```env
# Telegram
TELEGRAM_BOT_TOKEN=<your-token>
BOT_USERNAME=<your-username>

# AI Providers
OPENAI_API_KEY=<your-key>

# App
SECRET_KEY=<random-string-32-chars>
FLASK_ENV=production
FLASK_DEBUG=False
STORAGE_PATH=/app/storage

# Auto-generated by Railway
DATABASE_URL=postgresql://...
REDIS_URL=redis://...
PORT=5000  # Only for web service
```

### 3. Service Configuration

**Web Service:**
- Build Command: (auto-detected)
- Start Command: (from Procfile)
- Health Check Path: `/api/health`
- Health Check Timeout: 100

**Worker Service:**
- Build Command: (auto-detected)
- Start Command: `celery -A celery_config worker --loglevel=info --concurrency=2`
- Health Check: Disabled

### 4. Deployment Verification

#### Check Web Service Logs:
```
[INFO] Starting Socrate AI API server on port 5000
[INFO] Bot Username: YourBot
[INFO] Storage Path: /app/storage
```

#### Check Worker Service Logs:
```
[INFO] celery@worker ready
[INFO] registered tasks:
  - tasks.process_document_task
  - tasks.cleanup_old_documents
```

#### Check Redis Connection:
```bash
# In Railway web service shell
python -c "from celery_config import celery_app; print(celery_app.control.inspect().active())"
```

#### Test Health Endpoint:
```bash
curl https://your-app.up.railway.app/api/health
```

Expected:
```json
{
  "status": "healthy",
  "service": "Socrate AI Multi-tenant API",
  "version": "1.0.0"
}
```

## Local Testing Steps

### Prerequisites

- [ ] Python 3.10+ installed
- [ ] Docker installed (for Redis)
- [ ] Git repository cloned

### Setup Steps

1. **Install Dependencies**
   ```bash
   pip install -r requirements_multitenant.txt
   ```

2. **Start Redis**
   ```bash
   docker run -d -p 6379:6379 redis:7-alpine
   ```

3. **Configure Environment**
   ```bash
   cp .env.example .env
   # Edit .env with your values
   ```

4. **Initialize Database**
   ```bash
   python init_db.py
   ```

5. **Start Services** (choose one):

   **Option A: Manual (3 terminals)**
   ```bash
   # Terminal 1: Celery Worker
   celery -A celery_config worker --loglevel=info

   # Terminal 2: Flask API
   python api_server.py

   # Terminal 3: Monitor
   redis-cli MONITOR
   ```

   **Option B: Automated (Windows)**
   ```bash
   start_async_dev.bat
   ```

   **Option C: Docker Compose**
   ```bash
   docker-compose -f docker-compose.dev.yml up
   ```

6. **Run Tests**
   ```bash
   python test_async_processing.py
   ```

7. **Test in Browser**
   - Open http://localhost:5000
   - Login with Telegram
   - Upload a test PDF
   - Watch progress bar update in real-time

## Testing Checklist

### Unit Tests
- [ ] Database initialization (init_db.py)
- [ ] User creation and retrieval
- [ ] Document creation and status updates
- [ ] Multi-tenant isolation

### Integration Tests
- [ ] Celery worker connection
- [ ] Redis broker connection
- [ ] Task queueing and execution
- [ ] Status polling API
- [ ] Progress updates

### End-to-End Tests
- [ ] User login via Telegram
- [ ] Document upload via web UI
- [ ] Progress bar updates in real-time
- [ ] Document appears with "ready" status
- [ ] Tools button enabled after processing
- [ ] Document deletion works

### Performance Tests
- [ ] Upload 10MB PDF - completes in < 2 minutes
- [ ] Upload 50MB PDF - completes in < 10 minutes
- [ ] Multiple concurrent uploads (5 documents)
- [ ] Worker handles task queue properly
- [ ] No memory leaks over 1 hour

### Error Handling Tests
- [ ] Invalid file type - rejected before upload
- [ ] Storage quota exceeded - returns 413 error
- [ ] Worker crash - task retried (TODO: add retry)
- [ ] Redis unavailable - shows error to user
- [ ] Network error during polling - retries

## Production Monitoring

### Health Checks

**API Health:**
```bash
curl https://your-app.up.railway.app/api/health
```

**Celery Workers:**
```bash
# Via Railway CLI
railway run celery -A celery_config inspect active
```

**Redis:**
```bash
# Check connection count
railway run redis-cli INFO clients
```

### Key Metrics to Monitor

**Document Processing:**
- Average processing time
- Success rate
- Error rate
- Queue length

**Worker Performance:**
- Active tasks
- Completed tasks per hour
- Failed tasks
- Memory usage

**Redis:**
- Memory usage
- Connection count
- Operations per second

**Database:**
- Query performance
- Connection pool usage
- Storage used

### Alerts to Set Up

- [ ] Worker service down > 5 minutes
- [ ] Redis memory usage > 80%
- [ ] Document processing failure rate > 10%
- [ ] API response time > 5 seconds
- [ ] Storage quota exceeded for multiple users

## Rollback Plan

If async processing has issues in production:

1. **Quick Fix**: Restart worker service in Railway
   - No downtime for web service
   - Tasks will resume automatically

2. **Rollback to Synchronous**: (emergency only)
   ```python
   # In api_server.py, comment out async task:
   # task = process_document_task.delay(...)

   # Add synchronous processing:
   from tasks import process_document_task
   result = process_document_task(str(doc.id), user_id)
   ```

3. **Database State**: No schema changes needed
   - Document status field already supported
   - Can clear stuck documents manually:
   ```sql
   UPDATE documents SET status = 'failed'
   WHERE status = 'processing' AND created_at < NOW() - INTERVAL '1 hour';
   ```

## Success Criteria

### Functional Requirements
- [x] Documents upload without blocking
- [x] Progress updates shown in real-time
- [x] Processing completes successfully
- [x] Errors handled gracefully
- [x] Multi-tenant isolation maintained

### Non-Functional Requirements
- [ ] 99% uptime for API service
- [ ] 95% uptime for worker service (can tolerate brief restarts)
- [ ] < 5 second response time for API calls
- [ ] < 5 minute processing time for typical PDF
- [ ] Handles 100+ concurrent users

### User Experience
- [x] Intuitive upload flow
- [x] Real-time progress feedback
- [x] Clear error messages
- [x] No page refresh needed
- [x] Responsive on mobile

## Post-Deployment Tasks

### Immediate (within 24 hours)
- [ ] Monitor worker logs for errors
- [ ] Test upload from production UI
- [ ] Verify progress tracking works
- [ ] Check database for stuck documents
- [ ] Test with various file types/sizes

### Short-term (within 1 week)
- [ ] Add retry logic to tasks
- [ ] Implement Celery Beat for cleanup
- [ ] Add task analytics
- [ ] Optimize worker concurrency
- [ ] Set up monitoring alerts

### Long-term (within 1 month)
- [ ] Replace polling with WebSocket
- [ ] Add S3 storage backend
- [ ] Implement task prioritization
- [ ] Add distributed workers
- [ ] Optimize memvid encoder settings

## Support Resources

### Documentation
- [Celery Documentation](https://docs.celeryq.dev/)
- [Railway Documentation](https://docs.railway.app/)
- [Redis Documentation](https://redis.io/documentation)
- [Flask Documentation](https://flask.palletsprojects.com/)

### Internal Docs
- `DEPLOYMENT_GUIDE.md` - Deployment instructions
- `ASYNC_IMPLEMENTATION_SUMMARY.md` - Technical details
- `README_MULTITENANT.md` - Project overview

### Troubleshooting
See `ASYNC_IMPLEMENTATION_SUMMARY.md` section "Troubleshooting Guide"

---

## Final Status

**Implementation**: ✅ Complete

**Testing**: ⏳ Pending local tests

**Deployment**: ⏳ Ready for Railway deployment

**Documentation**: ✅ Complete

---

**Next Action**: Run local tests with `python test_async_processing.py`

**Date**: January 2025

**Version**: 1.0.0
